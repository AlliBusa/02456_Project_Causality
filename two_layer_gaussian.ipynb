{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data\n",
    "\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages needed for creating x \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Z and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E=[0.2, 2, 3, 5] # environmental factors\n",
    "S=[1,2,3,4]\n",
    "\n",
    "\n",
    "def generate_z_and_y(E,S):\n",
    "    beta_z1 = np.random.normal(0,1)\n",
    "    beta_z2 = np.random.normal(0,1)\n",
    "    beta_z3 = np.random.normal(0,1)\n",
    "    env_y = []\n",
    "    env_z = []\n",
    "\n",
    "    for i in range(len(E)):\n",
    "        # Draw beta\n",
    "        beta1 = np.random.normal(0,1)\n",
    "        beta2 = np.random.normal(0,1)\n",
    "        \n",
    "        # Create Z1\n",
    "        Z1=np.random.normal(beta1*E[i], 1, 1000)\n",
    "        #Z1=np.vstack((Z1, np.array([S[i]]*1000))).reshape(-1,1000).T\n",
    "        \n",
    "        # Create Z2\n",
    "        Z2=np.random.normal(2*beta2*E[i], 2, 1000)\n",
    "        #Z2=np.vstack((Z2, np.array([S[i]]*1000))).reshape(-1,1000).T\n",
    "\n",
    "        # Create Y\n",
    "        Y=np.zeros(1000)\n",
    "\n",
    "        # Create Z3\n",
    "        Z3=np.zeros(1000)\n",
    "        for i in range(len(Z1)):\n",
    "            Y[i] = np.random.normal(beta_z1*Z1[i]+beta_z2*Z2[i], 1)\n",
    "\n",
    "\n",
    "            Z3[i]=np.random.normal(3*beta_z3*Y[i], 1)\n",
    "\n",
    "        env_y.append(Y)\n",
    "        env_z.append(pd.DataFrame(np.vstack((Z1[:], Z2[:], Z3[:])).T))\n",
    "\n",
    "\n",
    "    Z=pd.concat([env_z[0], env_z[1], env_z[2], env_z[3]],axis=1)\n",
    "    Zs=np.zeros((1000, 4, 4))\n",
    "    # categories=[0,1,2,3]\n",
    "    for i in range(len(E)):#categories:\n",
    "        Zs[:,:3,i]=env_z[i]\n",
    "        Zs[:,3,i]=i+1\n",
    "\n",
    "    return Zs, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs, Y = generate_z_and_y(E,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hyperparameters\n",
    "num_classes = 10\n",
    "num_l1 = 6\n",
    "num_features = 3\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_output):\n",
    "        super(Net, self).__init__()  \n",
    "        # hidden layer\n",
    "        self.W_1 = Parameter(init.xavier_normal_(torch.Tensor(num_hidden, num_features)))\n",
    "        self.b_1 = Parameter(init.constant_(torch.Tensor(num_hidden), 0))\n",
    "        # output layer\n",
    "        self.W_2 = Parameter(init.xavier_normal_(torch.Tensor(num_output, num_hidden)))\n",
    "        self.b_2 = Parameter(init.constant_(torch.Tensor(num_output), 0))\n",
    "        # define activation function in constructor\n",
    "        self.activation = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.W_1, self.b_1)\n",
    "        x = self.activation(x)\n",
    "        x = F.linear(x, self.W_2, self.b_2)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_features, num_l1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 10])\n"
     ]
    }
   ],
   "source": [
    "print(net(torch.from_numpy(Zs[:,:3,1].astype(\"float32\"))).size())\n",
    "\n",
    "X = net(torch.from_numpy(Zs[:,:3,1].astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Data to Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to export the data to csvs\n",
    "# Will remove after next github push\n",
    "\n",
    "# # turn all data into Dataframes \n",
    "# y_df = pd.DataFrame(Y, columns = ['Y'])\n",
    "# x_df = pd.DataFrame(X)\n",
    "# # zs_df = pd.DataFrame(Zs, columns = [\"Z1\", \"Z2\", \"Z3\", \"Environments\"])\n",
    "# # save data to file \n",
    "# y_df.to_csv('y.csv') \n",
    "# # zs_df.to_csv('zs.csv') \n",
    "# x_df.to_csv('x.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomSyntheticDataset(Dataset):\n",
    "    def __init__(self,X,Zs,Y):\n",
    "        self.X = X\n",
    "        self.Zs = Zs\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get label from Y \n",
    "        label = self.Y[idx,:]\n",
    "        # get Zs for each env't\n",
    "        selected_zs = self.Zs[idx,:,:] \n",
    "        # get X \n",
    "        selected_x = self.X[idx,:]\n",
    "        return selected_x, selected_zs, label\n",
    "\n",
    "    def return_training(self):\n",
    "        return X\n",
    "    \n",
    "    def return_testing(self):\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_instance = CustomSyntheticDataset(X,Zs,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying VAE Exercise Data Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_train[:900,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "# data imports \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "#classes = [*range(1, len(E), 1)] # environments\n",
    "#def stratified_sampler(labels):\n",
    "#    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "#    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "#    indices = torch.from_numpy(indices)\n",
    "#    return SubsetRandomSampler(indices)\n",
    "\n",
    "dset_train = dataset_instance.return_training()\n",
    "dset_test = dataset_instance.return_testing()\n",
    "\n",
    "batch_size = 64\n",
    "eval_batch_size = 100\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train[:910,:], batch_size=batch_size)\n",
    "test_loader  = DataLoader(dset_train[910:,:], batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        return self.sample_epsilon() * self.sigma + self.mu \n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        # create a normal distribution to sample from \n",
    "        m = Normal(self.mu, self.sigma)\n",
    "        # get probability of choosing z from that distribution\n",
    "        return m.log_prob(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (en1): Linear(in_features=10, out_features=5, bias=True)\n",
      "  (en2): Linear(in_features=5, out_features=6, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (de1): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (de2_1): Linear(in_features=5, out_features=10, bias=True)\n",
      "  (de2_2): Linear(in_features=5, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    \"\"\"A Variational Autoencoder with\n",
    "    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`\n",
    "    * a Gaussian prior `p(z) = N(z | 0, I)`\n",
    "    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "\n",
    "        self.en1 = nn.Linear(self.observation_features, 5)\n",
    "        self.en2 = nn.Linear(5, 2*latent_features)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        self.de1 = nn.Linear(latent_features, 5)\n",
    "        self.de2_1= nn.Linear(5, self.observation_features)\n",
    "        self.de2_2 = nn.Linear(5, self.observation_features)\n",
    "\n",
    "        # Step 4:\n",
    "        # define the parameters of the prior, chosen as p(z) = N(0, I)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "        # Define the rest of the encoding architecture\n",
    "    def encoder(self, x):\n",
    "        x = self.activation(self.en1(x))\n",
    "        x = self.en2(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self,z):\n",
    "        z = self.activation(self.de1(z))\n",
    "        z1 = self.de2_1(z)\n",
    "        z2 = self.de2_2(z)\n",
    "        # print(f\"sizes {z1.size()}, {z2.size()}\")\n",
    "        output = torch.concat([z1,z2], 0)\n",
    "        # print(f\"output size {output.size()}\")\n",
    "        return output\n",
    "    \n",
    "        \n",
    "    def posterior(self, x:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(x|x) = N(z | mu(x), sigma(x))`\"\"\"\n",
    "        \n",
    "        # compute the parameters of the posterior\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | mu(x), sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def prior(self, batch_size:int=1)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        # return the distribution `p(z)`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        decoder_output = self.decoder(z)\n",
    "        mu, log_sigma =  decoder_output.chunk(2, dim=0)\n",
    "        # px_logits = px_logits.view(-1, *self.input_shape) # reshape the output\n",
    "        # print(f\"decoder output: {decoder_output.size()} \\n mu size : {mu.size()} \\n\")\n",
    "        # return Normal(mu, log_sigma**2)\n",
    "        return {\"mu\":mu, \"log_sigma\":log_sigma}#torch.distributions.MultivariateNormal(mu, )\n",
    "        \n",
    "\n",
    "    def forward(self, x) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x)\n",
    "        \n",
    "        # define the prior p(z) # Just assume a standard prior with mean 0 and var 1\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        #print(qz)\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        # Decode\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "    \n",
    "    \n",
    "    def sample_from_prior(self, batch_size:int=100):\n",
    "        \"\"\"sample z~p(z) and return p(x|z)\"\"\"\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "        \n",
    "        # sample the prior \n",
    "        z = pz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'z': z}\n",
    "\n",
    "\n",
    "latent_features = 3\n",
    "vae = VariationalAutoencoder(X[0].shape, latent_features)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Variational Inference (ie Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(x:Tensor) -> Tensor:\n",
    "    \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "    return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta:float=1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        \n",
    "    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:\n",
    "        \n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "        \n",
    "        \n",
    "        # unpack outputs\n",
    "        # Get parameters of the prior and posterior and px and z's\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        log_sigma = px[\"log_sigma\"]\n",
    "        exp_sigma = torch.exp(log_sigma)\n",
    "        mu = px[\"mu\"]\n",
    "        # evaluate log probabilities\n",
    "        # Whats the probability of getting x and z given the estimated distributions\n",
    "        # log_px = reduce(px.log_prob(x))\n",
    "\n",
    "        # log_pz = reduce(pz.log_prob(z))\n",
    "        # log_qz = reduce(qz.log_prob(z))\n",
    "        \n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^beta = E_q [ log p(x|z) ] - beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        # kl = log_qz - log_pz\n",
    "        reconstruction_loss_inner = (-(0.5 * np.log(2 * np.pi) + 0.5 * log_sigma) -\n",
    "                      0.5 * ((x - mu)**2 / exp_sigma))\n",
    "        # print(f\"reconstruction loss inner type {type(reconstruction_loss_inner)} and size {reconstruction_loss_inner.size()}\")\n",
    "        reconstruction_loss = reconstruction_loss_inner.sum(axis=1).mean(axis=0)\n",
    "        kl_gauss_inner = 1 + log_sigma - mu**2 - exp_sigma\n",
    "        kl_gauss = 0.5 * kl_gauss_inner.sum(axis=1)\n",
    "        \n",
    "        # print(f\"gauss loss inner type {type(kl_gauss_inner)} and size {kl_gauss_inner.size()}\")\n",
    "        elbo = reconstruction_loss - kl_gauss # <- your code here\n",
    "        beta_elbo =  reconstruction_loss - self.beta*kl_gauss # <- your code here\n",
    "        \n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            # diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            diagnostics = {'elbo': elbo, 'recon loss':reconstruction_loss, 'kl gauss': kl_gauss}\n",
    "            _, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "            print(f\"x shape {x.size()} \\n mu shape {mu.size()}\") \n",
    "            x = x.cpu().numpy()\n",
    "            mu = mu.cpu().numpy()\n",
    "            index = [*range(0, len(x), 1)]\n",
    "\n",
    "            print(f\"x shape {np.size(x)} \\n mu shape {np.size(mu)} \\n index {len(index)}\")\n",
    "\n",
    "            plt.scatter(index, x, color=\"blue\", alpha=0.3)\n",
    "            plt.scatter(index, mu, color=\"red\", alpha=0.3)\n",
    "\n",
    "            ax = plt.gca()\n",
    "            howblack = 0.15\n",
    "            ax.set_facecolor((howblack, howblack, howblack))\n",
    "            plt.show()\n",
    "\n",
    "            \n",
    "        return loss, diagnostics, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization \n",
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 3\n",
    "vae = VariationalAutoencoder(X[0].shape, latent_features)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 1\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cuda:0\n",
      "x shape torch.Size([64, 10]) \n",
      " mu shape torch.Size([64, 10])\n",
      "x shape 640 \n",
      " mu shape 640 \n",
      " index 64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4357/1440491167.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# perform a forward pass through the model and compute the ELBO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagnostics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4357/1777304435.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, model, x)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x shape {np.size(x)} \\n mu shape {np.size(mu)} \\n index {len(index)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"red\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, data, **kwargs)\u001b[0m\n\u001b[1;32m   3066\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m         edgecolors=None, plotnonfinite=False, data=None, **kwargs):\n\u001b[0;32m-> 3068\u001b[0;31m     __ret = gca().scatter(\n\u001b[0m\u001b[1;32m   3069\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3070\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1359\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4496\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4498\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Training Loop \n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# move the model to the device\n",
    "vae = vae.to(device)\n",
    "\n",
    "# training..\n",
    "while epoch < num_epochs:\n",
    "    epoch+= 1\n",
    "    training_epoch_data = defaultdict(list)\n",
    "    vae.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    #for x, y in train_loader:\n",
    "    for x in train_loader:\n",
    "    \n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gather data for the current bach\n",
    "        for k, v in diagnostics.items():\n",
    "            training_epoch_data[k] += [v.mean().item()]\n",
    "            \n",
    "\n",
    "    # gather data for the full epoch\n",
    "    for k, v in training_epoch_data.items():\n",
    "        training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "    # Evaluate on a single batch, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        #x, y = next(iter(test_loader))\n",
    "        x= next(iter(test_loader))\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBOwhy \n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        # gather data for the validation step\n",
    "        for k, v in diagnostics.items():\n",
    "            validation_data[k] += [v.mean().item()]\n",
    "    \n",
    "    # Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples\n",
    "    # make_vae_plots(vae, x, y, outputs, training_data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval is a \"confidence interval\" of the mean difference. So it tells you the 95% bounds for the mean difference between two models. The fact that it's positive or negative implies that the mean test error isÂ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58258/1013125001.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_from_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'px'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "outputs['z']\n",
    "px = vae.sample_from_prior(batch_size=x.size(0))['px']\n",
    "x_samples = px.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1979,  1.4612,  0.4428, -0.9841,  0.1299,  0.4169, -0.7696,  0.8922,\n",
       "        -1.1782, -0.0525], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -6.1260,   0.6893,  -7.4136,  -0.7852,  -3.6001,  -0.5520,  -8.5079,\n",
       "        -11.0923,  -6.4012,  -0.7096], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[910:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4620,  0.2598, -1.6850, -0.0661, -0.7311, -0.1186, -1.9063, -2.4087,\n",
       "        -1.4396, -0.1992], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'latent_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58258/3126076475.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mVariationalAutoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'latent_features'"
     ]
    }
   ],
   "source": [
    "VariationalAutoencoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee89bb07d3fa5f9c0a8bd127b3056783b076f56308f3ae1a55a1b4c1c97796ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
