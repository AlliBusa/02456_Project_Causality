{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Synthetic Data\n",
    "\n",
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# packages needed for creating x \n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Z and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E=[0.2, 2, 3, 5] # environmental factors\n",
    "S=[1,2,3,4]\n",
    "\n",
    "\n",
    "def generate_z_and_y(E,S):\n",
    "    beta_z1 = np.random.normal(0,1)\n",
    "    beta_z2 = np.random.normal(0,1)\n",
    "    beta_z3 = np.random.normal(0,1)\n",
    "    env_y = []\n",
    "    env_z = []\n",
    "\n",
    "    for i in range(len(E)):\n",
    "        # Draw beta\n",
    "        beta1 = np.random.normal(0,1)\n",
    "        beta2 = np.random.normal(0,1)\n",
    "        \n",
    "        # Create Z1\n",
    "        Z1=np.random.normal(beta1*E[i], 1, 1000)\n",
    "        #Z1=np.vstack((Z1, np.array([S[i]]*1000))).reshape(-1,1000).T\n",
    "        \n",
    "        # Create Z2\n",
    "        Z2=np.random.normal(2*beta2*E[i], 2, 1000)\n",
    "        #Z2=np.vstack((Z2, np.array([S[i]]*1000))).reshape(-1,1000).T\n",
    "\n",
    "        # Create Y\n",
    "        Y=np.zeros(1000)\n",
    "\n",
    "        # Create Z3\n",
    "        Z3=np.zeros(1000)\n",
    "        for i in range(len(Z1)):\n",
    "            Y[i] = np.random.normal(beta_z1*Z1[i]+beta_z2*Z2[i], 1)\n",
    "\n",
    "\n",
    "            Z3[i]=np.random.normal(3*beta_z3*Y[i], 1)\n",
    "\n",
    "        env_y.append(Y)\n",
    "        env_z.append(pd.DataFrame(np.vstack((Z1[:], Z2[:], Z3[:])).T))\n",
    "\n",
    "\n",
    "    Z=pd.concat([env_z[0], env_z[1], env_z[2], env_z[3]],axis=1)\n",
    "    Zs=np.zeros((1000, 4, 4))\n",
    "    # categories=[0,1,2,3]\n",
    "    for i in range(len(E)):#categories:\n",
    "        Zs[:,:3,i]=env_z[i]\n",
    "        Zs[:,3,i]=i+1\n",
    "\n",
    "    return Zs, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Zs, Y = generate_z_and_y(E,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Hyperparameters\n",
    "num_classes = 10\n",
    "num_l1 = 6\n",
    "num_features = 3\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features, num_hidden, num_output):\n",
    "        super(Net, self).__init__()  \n",
    "        # hidden layer\n",
    "        self.W_1 = Parameter(init.xavier_normal_(torch.Tensor(num_hidden, num_features)))\n",
    "        self.b_1 = Parameter(init.constant_(torch.Tensor(num_hidden), 0))\n",
    "        # output layer\n",
    "        self.W_2 = Parameter(init.xavier_normal_(torch.Tensor(num_output, num_hidden)))\n",
    "        self.b_2 = Parameter(init.constant_(torch.Tensor(num_output), 0))\n",
    "        # define activation function in constructor\n",
    "        self.activation = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.linear(x, self.W_1, self.b_1)\n",
    "        x = self.activation(x)\n",
    "        x = F.linear(x, self.W_2, self.b_2)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net(num_features, num_l1, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 10])\n"
     ]
    }
   ],
   "source": [
    "print(net(torch.from_numpy(Zs[:,:3,1].astype(\"float32\"))).size())\n",
    "\n",
    "X = net(torch.from_numpy(Zs[:,:3,1].astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reformatting Data to Pytorch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to export the data to csvs\n",
    "# Will remove after next github push\n",
    "\n",
    "# # turn all data into Dataframes \n",
    "# y_df = pd.DataFrame(Y, columns = ['Y'])\n",
    "# x_df = pd.DataFrame(X)\n",
    "# # zs_df = pd.DataFrame(Zs, columns = [\"Z1\", \"Z2\", \"Z3\", \"Environments\"])\n",
    "# # save data to file \n",
    "# y_df.to_csv('y.csv') \n",
    "# # zs_df.to_csv('zs.csv') \n",
    "# x_df.to_csv('x.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomSyntheticDataset(Dataset):\n",
    "    def __init__(self,X,Zs,Y):\n",
    "        self.X = X\n",
    "        self.Zs = Zs\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get label from Y \n",
    "        label = self.Y[idx,:]\n",
    "        # get Zs for each env't\n",
    "        selected_zs = self.Zs[idx,:,:] \n",
    "        # get X \n",
    "        selected_x = self.X[idx,:]\n",
    "        return selected_x, selected_zs, label\n",
    "\n",
    "    def return_training(self):\n",
    "        return X\n",
    "    \n",
    "    def return_testing(self):\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_instance = CustomSyntheticDataset(X,Zs,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modifying VAE Exercise Data Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dset_train[:900,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display, clear_output\n",
    "import numpy as np\n",
    "%matplotlib nbagg\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "from torch.distributions import Bernoulli\n",
    "\n",
    "# data imports \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from functools import reduce\n",
    "\n",
    "#classes = [*range(1, len(E), 1)] # environments\n",
    "#def stratified_sampler(labels):\n",
    "#    \"\"\"Sampler that only picks datapoints corresponding to the specified classes\"\"\"\n",
    "#    (indices,) = np.where(reduce(lambda x, y: x | y, [labels.numpy() == i for i in classes]))\n",
    "#    indices = torch.from_numpy(indices)\n",
    "#    return SubsetRandomSampler(indices)\n",
    "\n",
    "dset_train = dataset_instance.return_training()\n",
    "dset_test = dataset_instance.return_testing()\n",
    "\n",
    "batch_size = 64\n",
    "eval_batch_size = 100\n",
    "# The loaders perform the actual work\n",
    "train_loader = DataLoader(dset_train[:910,:], batch_size=batch_size)\n",
    "test_loader  = DataLoader(dset_train[910:,:], batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Gaussian Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "from torch.nn.functional import softplus\n",
    "from torch.distributions import Distribution\n",
    "from torch.distributions import Normal\n",
    "\n",
    "class ReparameterizedDiagonalGaussian(Distribution):\n",
    "    \"\"\"\n",
    "    A distribution `N(y | mu, sigma I)` compatible with the reparameterization trick given `epsilon ~ N(0, 1)`.\n",
    "    \"\"\"\n",
    "    def __init__(self, mu: Tensor, log_sigma:Tensor):\n",
    "        assert mu.shape == log_sigma.shape, f\"Tensors `mu` : {mu.shape} and ` log_sigma` : {log_sigma.shape} must be of the same shape\"\n",
    "        self.mu = mu\n",
    "        self.sigma = log_sigma.exp()\n",
    "        \n",
    "    def sample_epsilon(self) -> Tensor:\n",
    "        \"\"\"`\\eps ~ N(0, I)`\"\"\"\n",
    "        return torch.empty_like(self.mu).normal_()\n",
    "        \n",
    "    def sample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (without gradients)\"\"\"\n",
    "        with torch.no_grad():\n",
    "            return self.rsample()\n",
    "        \n",
    "    def rsample(self) -> Tensor:\n",
    "        \"\"\"sample `z ~ N(z | mu, sigma)` (with the reparameterization trick) \"\"\"\n",
    "        return self.sample_epsilon() * self.sigma + self.mu \n",
    "        \n",
    "    def log_prob(self, z:Tensor) -> Tensor:\n",
    "        \"\"\"return the log probability: log `p(z)`\"\"\"\n",
    "        # create a normal distribution to sample from \n",
    "        m = Normal(self.mu, self.sigma)\n",
    "        # get probability of choosing z from that distribution\n",
    "        return m.log_prob(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VariationalAutoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=6, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=3, out_features=10, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "\n",
    "class VariationalAutoencoder(nn.Module):\n",
    "    \"\"\"A Variational Autoencoder with\n",
    "    * a Bernoulli observation model `p_\\theta(x | z) = B(x | g_\\theta(z))`\n",
    "    * a Gaussian prior `p(z) = N(z | 0, I)`\n",
    "    * a Gaussian posterior `q_\\phi(z|x) = N(z | \\mu(x), \\sigma(x))`\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_shape:torch.Size, latent_features:int) -> None:\n",
    "        super(VariationalAutoencoder, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.latent_features = latent_features\n",
    "        self.observation_features = np.prod(input_shape)\n",
    "        \n",
    "\n",
    "        # Inference Network\n",
    "        # Encode the observation `x` into the parameters of the posterior distribution\n",
    "        # q_phi(z|x) = N(z | mu(x), sigma(x)),\n",
    "        # mu(x),\n",
    "        # log(sigma(x)) = h_phi(x)`\n",
    "        \n",
    "        # Step 1:\n",
    "        # Define input dimensions -> self.input_shape\n",
    "        # Step 2:\n",
    "        # Define the rest of the encoding architecture\n",
    "        self.encoder = nn.Sequential(\n",
    "             nn.Linear(in_features=self.observation_features, out_features=10),\n",
    "             nn.ReLU(),\n",
    "            # nn.Linear(in_features=1024, out_features=512),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_features=512, out_features=256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_features=256, out_features=128),\n",
    "            # nn.ReLU(),\n",
    "            # A Gaussian is fully characterised by its mean \\mu and variance \\sigma**2\n",
    "            nn.Linear(in_features=10, out_features=2*latent_features) # <- note the 2*latent_features\n",
    "        )\n",
    "        \n",
    "        # Generative Model\n",
    "        # Decode the latent sample `z` into the parameters of the observation model\n",
    "        # `p_theta(x | z) = prod_i B(x_i | g_theta(x))`\n",
    "        \n",
    "        # Step 3:\n",
    "        # Decode from latent space back to X\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(in_features=latent_features, out_features=10),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(in_features=128, out_features=256),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_features=256, out_features=512),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(in_features=512, out_features=1024),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(in_features=10, out_features=self.observation_features)\n",
    "            # 2*self.observation_features\n",
    "            # Index which of the outputs are mu and which are sigma\n",
    "        )\n",
    "        \n",
    "        # Step 4:\n",
    "        # define the parameters of the prior, chosen as p(z) = N(0, I)\n",
    "        self.register_buffer('prior_params', torch.zeros(torch.Size([1, 2*latent_features])))\n",
    "        \n",
    "    def posterior(self, x:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `q(x|x) = N(z | mu(x), sigma(x))`\"\"\"\n",
    "        \n",
    "        # compute the parameters of the posterior\n",
    "        h_x = self.encoder(x)\n",
    "        mu, log_sigma =  h_x.chunk(2, dim=-1)\n",
    "        \n",
    "        # return a distribution `q(x|x) = N(z | mu(x), sigma(x))`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def prior(self, batch_size:int=1)-> Distribution:\n",
    "        \"\"\"return the distribution `p(z)`\"\"\"\n",
    "        prior_params = self.prior_params.expand(batch_size, *self.prior_params.shape[-1:])\n",
    "        mu, log_sigma = prior_params.chunk(2, dim=-1)\n",
    "        \n",
    "        # return the distribution `p(z)`\n",
    "        return ReparameterizedDiagonalGaussian(mu, log_sigma)\n",
    "    \n",
    "    def observation_model(self, z:Tensor) -> Distribution:\n",
    "        \"\"\"return the distribution `p(x|z)`\"\"\"\n",
    "        px_logits = self.decoder(z)\n",
    "        #pdb.set_trace()\n",
    "        px_logits = px_logits.view(-1, *self.input_shape) # reshape the output\n",
    "        #pdb.set_trace()\n",
    "        #return Bernoulli(logits=px_logits, validate_args=False)\n",
    "        return Normal(px_logits, 0.1)\n",
    "        \n",
    "\n",
    "    def forward(self, x) -> Dict[str, Any]:\n",
    "        \"\"\"compute the posterior q(z|x) (encoder), sample z~q(z|x) and return the distribution p(x|z) (decoder)\"\"\"\n",
    "        \n",
    "        # flatten the input\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # define the posterior q(z|x) / encode x into q(z|x)\n",
    "        qz = self.posterior(x)\n",
    "        \n",
    "        # define the prior p(z) # Just assume a standard prior with mean 0 and var 1\n",
    "        pz = self.prior(batch_size=x.size(0))\n",
    "        \n",
    "        # sample the posterior using the reparameterization trick: z ~ q(z | x)\n",
    "        z = qz.rsample()\n",
    "        #print(qz)\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        # Decode\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'qz': qz, 'z': z}\n",
    "    \n",
    "    \n",
    "    def sample_from_prior(self, batch_size:int=100):\n",
    "        \"\"\"sample z~p(z) and return p(x|z)\"\"\"\n",
    "        \n",
    "        # define the prior p(z)\n",
    "        pz = self.prior(batch_size=batch_size)\n",
    "        \n",
    "        # sample the prior \n",
    "        z = pz.rsample()\n",
    "        \n",
    "        # define the observation model p(x|z) = B(x | g(z))\n",
    "        px = self.observation_model(z)\n",
    "        \n",
    "        return {'px': px, 'pz': pz, 'z': z}\n",
    "\n",
    "\n",
    "latent_features = 3\n",
    "vae = VariationalAutoencoder(X[0].shape, latent_features)\n",
    "print(vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Variational Inference (ie Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(x:Tensor) -> Tensor:\n",
    "    \"\"\"for each datapoint: sum over all dimensions\"\"\"\n",
    "    return x.view(x.size(0), -1).sum(dim=1)\n",
    "\n",
    "class VariationalInference(nn.Module):\n",
    "    def __init__(self, beta:float=1.):\n",
    "        super().__init__()\n",
    "        self.beta = beta\n",
    "        self.a=0\n",
    "        \n",
    "    def forward(self, model:nn.Module, x:Tensor) -> Tuple[Tensor, Dict]:\n",
    "        \n",
    "        # forward pass through the model\n",
    "        outputs = model(x)\n",
    "        \n",
    "        # unpack outputs\n",
    "        # Get parameters of the prior and posterior and px and z's\n",
    "        px, pz, qz, z = [outputs[k] for k in [\"px\", \"pz\", \"qz\", \"z\"]]\n",
    "        \n",
    "        # evaluate log probabilities\n",
    "        # Whats the probability of getting x and z given the estimated distributions\n",
    "        log_px = reduce(px.log_prob(x))\n",
    "        #pdb.set_trace()\n",
    "        self.a+=1\n",
    "        #print(self.a)\n",
    "        #pdb.set_trace()\n",
    "        #print(qz.mu)\n",
    "        #print(qz.mu.shape)\n",
    "        log_pz = reduce(pz.log_prob(z))\n",
    "        log_qz = reduce(qz.log_prob(z))\n",
    "        \n",
    "        # compute the ELBO with and without the beta parameter: \n",
    "        # `L^beta = E_q [ log p(x|z) ] - beta * D_KL(q(z|x) | p(z))`\n",
    "        # where `D_KL(q(z|x) | p(z)) = log q(z|x) - log p(z)`\n",
    "        kl = log_qz - log_pz\n",
    "        elbo = log_px - kl # <- your code here\n",
    "        beta_elbo =  log_px - self.beta*kl # <- your code here\n",
    "        \n",
    "        # loss\n",
    "        loss = -beta_elbo.mean()\n",
    "        \n",
    "        # prepare the output\n",
    "        with torch.no_grad():\n",
    "            diagnostics = {'elbo': elbo, 'log_px':log_px, 'kl': kl}\n",
    "            \n",
    "        return loss, diagnostics, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialization \n",
    "from collections import defaultdict\n",
    "# define the models, evaluator and optimizer\n",
    "\n",
    "# VAE\n",
    "latent_features = 3\n",
    "vae = VariationalAutoencoder(X[0].shape, latent_features)\n",
    "\n",
    "# Evaluator: Variational Inference\n",
    "beta = 1\n",
    "vi = VariationalInference(beta=beta)\n",
    "\n",
    "# The Adam optimizer works really well with VAEs.\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
    "\n",
    "# define dictionary to store the training curves\n",
    "training_data = defaultdict(list)\n",
    "validation_data = defaultdict(list)\n",
    "\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Using device: cuda:0\n",
      "> \u001b[1;32mc:\\users\\mathi\\appdata\\local\\temp\\ipykernel_24060\\3282771200.py\u001b[0m(88)\u001b[0;36mobservation_model\u001b[1;34m()\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  px_logits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.6038e-01, -1.7973e-01, -7.6791e-02,  5.2658e-01, -5.2946e-01,\n",
      "         -3.0681e-01, -7.6673e-02,  1.4967e-01, -1.5646e-01,  2.1208e-01],\n",
      "        [-7.8729e-02, -1.7756e-01,  9.3775e-03,  3.7966e-01, -3.4231e-01,\n",
      "         -2.7169e-01, -6.1950e-02,  1.0436e-01, -1.7387e-01,  1.3353e-01],\n",
      "        [-1.6048e-01, -1.8042e-01,  8.3689e-02,  4.4668e-01, -4.3105e-01,\n",
      "         -2.2230e-01, -1.3759e-01,  1.3283e-01, -2.2588e-01,  1.4186e-01],\n",
      "        [-2.4470e-01, -1.6862e-01,  5.3039e-02,  5.3907e-01, -5.7141e-01,\n",
      "         -2.2166e-01, -1.8437e-01,  1.6131e-01, -2.2147e-01,  1.5448e-01],\n",
      "        [-3.1479e-01, -2.1602e-01,  3.3857e-04,  5.3210e-01, -6.5576e-01,\n",
      "         -2.3715e-01, -2.1564e-01,  2.2998e-01, -2.6311e-01,  1.6425e-01],\n",
      "        [-1.5334e-01, -1.7334e-01,  4.0487e-01,  2.8975e-01, -2.6358e-01,\n",
      "          5.7000e-02, -1.4254e-01, -3.7622e-02, -3.9097e-01,  9.4086e-02],\n",
      "        [-1.2649e-01, -2.3768e-01,  1.5734e-01,  3.6170e-01, -3.2223e-01,\n",
      "         -2.0186e-01, -1.0256e-01,  1.4529e-01, -2.7376e-01,  1.4286e-01],\n",
      "        [-2.5854e-02, -2.0857e-01,  1.2849e-01,  1.9850e-01, -1.1288e-01,\n",
      "         -1.1999e-01, -1.1080e-01,  8.3694e-02, -3.4206e-01,  3.8342e-02],\n",
      "        [-3.4972e-01, -2.4214e-01,  4.4728e-01,  4.6669e-01, -4.9913e-01,\n",
      "          1.7613e-01, -1.2461e-01,  2.0160e-02, -4.3033e-01,  2.8551e-01],\n",
      "        [-1.2877e-01, -1.3805e-01, -1.0248e-01,  5.0432e-01, -5.0331e-01,\n",
      "         -3.1739e-01, -8.7871e-02,  1.1851e-01, -1.3354e-01,  1.8284e-01],\n",
      "        [-6.8293e-02, -1.2477e-01,  5.1746e-02,  3.4026e-01, -2.9119e-01,\n",
      "         -2.3059e-01, -9.4456e-02,  7.6413e-02, -2.1417e-01,  6.7405e-02],\n",
      "        [-5.3871e-02, -2.6682e-01,  1.3601e-01,  1.8029e-01, -1.4640e-01,\n",
      "         -5.4240e-02, -1.7353e-01,  9.7275e-02, -3.9468e-01,  7.7763e-02],\n",
      "        [-1.5117e-01, -2.5605e-01, -2.3264e-01,  5.8270e-01, -5.9212e-01,\n",
      "         -4.0419e-01,  5.8888e-02,  2.0432e-01, -1.0810e-01,  3.2964e-01],\n",
      "        [-1.1663e-01, -1.7140e-01, -1.6023e-01,  5.0973e-01, -5.0329e-01,\n",
      "         -3.5112e-01, -1.5170e-02,  1.3548e-01, -1.1114e-01,  2.1579e-01],\n",
      "        [-2.5525e-01, -1.7467e-01,  5.3768e-02,  5.5699e-01, -5.8886e-01,\n",
      "         -2.2036e-01, -1.8201e-01,  1.6753e-01, -2.2113e-01,  1.6498e-01],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-1.6373e-01, -1.8682e-01, -1.0243e-01,  5.4280e-01, -5.4914e-01,\n",
      "         -3.2122e-01, -6.2367e-02,  1.5752e-01, -1.4741e-01,  2.2971e-01],\n",
      "        [-5.7955e-02, -4.0551e-02,  6.7011e-02,  3.0500e-01, -2.4590e-01,\n",
      "         -1.8200e-01, -1.3314e-01,  4.3171e-02, -2.7059e-01, -1.7676e-02],\n",
      "        [-3.5453e-01, -2.4981e-01,  5.1624e-02,  5.7137e-01, -7.1870e-01,\n",
      "         -1.9398e-01, -2.0643e-01,  2.4505e-01, -2.8618e-01,  2.1348e-01],\n",
      "        [-8.9110e-02, -2.4780e-01,  5.5467e-02,  3.6037e-01, -3.1533e-01,\n",
      "         -2.5956e-01, -2.4477e-02,  1.4816e-01, -2.3319e-01,  1.7508e-01],\n",
      "        [-6.8156e-02, -1.6712e-01,  1.2189e-01,  3.0388e-01, -2.4665e-01,\n",
      "         -2.0621e-01, -9.5692e-02,  9.3449e-02, -2.5683e-01,  7.5592e-02],\n",
      "        [-3.9039e-01, -3.7294e-01,  4.5233e-02,  4.6749e-01, -7.4887e-01,\n",
      "         -9.8813e-02, -2.2862e-01,  3.0107e-01, -3.9188e-01,  2.6396e-01],\n",
      "        [-7.3858e-02, -1.7916e-01,  1.9624e-01,  2.7283e-01, -2.0994e-01,\n",
      "         -1.7018e-01, -1.2273e-01,  1.0092e-01, -3.1222e-01,  6.4242e-02],\n",
      "        [-1.7699e-01, -2.4021e-01, -3.7135e-01,  6.8583e-01, -7.2084e-01,\n",
      "         -4.6937e-01,  8.6884e-02,  2.1890e-01, -4.2924e-02,  3.8621e-01],\n",
      "        [-1.0665e-01, -2.1615e-01,  3.1893e-01,  2.4347e-01, -2.0290e-01,\n",
      "          2.5538e-02, -1.4352e-01,  2.5604e-04, -3.9085e-01,  9.6840e-02],\n",
      "        [-1.7935e-01, -2.4773e-01,  1.3951e-01,  4.3540e-01, -4.1411e-01,\n",
      "         -2.0362e-01, -1.1072e-01,  1.7071e-01, -2.6901e-01,  1.7351e-01],\n",
      "        [-2.4571e-01, -1.5705e-01, -1.2173e-01,  4.5666e-01, -6.0874e-01,\n",
      "         -3.1348e-01, -1.9978e-01,  1.9315e-01, -2.1485e-01,  1.2532e-01],\n",
      "        [-1.2010e-01, -1.3106e-01, -2.0782e-01,  5.3887e-01, -5.3970e-01,\n",
      "         -3.6409e-01, -2.4806e-02,  1.2096e-01, -8.6614e-02,  2.0435e-01],\n",
      "        [-1.2002e-01, -2.5886e-01,  5.2755e-02,  2.3125e-01, -2.7530e-01,\n",
      "         -1.2252e-01, -2.1905e-01,  1.7847e-01, -3.7983e-01,  6.8722e-02],\n",
      "        [-1.0921e-01, -1.0783e-01, -8.6978e-02,  4.7252e-01, -4.6301e-01,\n",
      "         -3.0325e-01, -1.0187e-01,  9.2940e-02, -1.3271e-01,  1.4181e-01],\n",
      "        [-6.0335e-02, -1.8338e-01,  1.5630e-01,  2.7249e-01, -2.0519e-01,\n",
      "         -1.9019e-01, -8.4556e-02,  9.7453e-02, -2.8239e-01,  6.7411e-02],\n",
      "        [-3.6424e-02, -2.4299e-01,  1.6231e-01,  1.9402e-01, -1.1248e-01,\n",
      "         -7.3672e-02, -1.3275e-01,  6.5673e-02, -3.6533e-01,  6.9486e-02],\n",
      "        [-2.0378e-01, -1.4997e-01, -4.2446e-01,  7.5697e-01, -8.1610e-01,\n",
      "         -4.7585e-01,  1.2197e-02,  1.8521e-01,  1.8123e-03,  3.5541e-01],\n",
      "        [-1.0172e-01, -1.8411e-01,  3.5254e-02,  2.9779e-01, -3.1855e-01,\n",
      "         -1.8618e-01, -1.8689e-01,  1.4100e-01, -2.9751e-01,  7.6315e-02],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-6.9276e-02, -1.7687e-01,  1.9058e-01,  2.6803e-01, -2.0237e-01,\n",
      "         -1.7113e-01, -1.1390e-01,  9.8423e-02, -3.1008e-01,  5.9424e-02],\n",
      "        [-2.2571e-01, -2.9979e-01,  2.8899e-01,  2.8473e-01, -4.0189e-01,\n",
      "          1.0443e-01, -2.2156e-01,  6.1459e-02, -4.2868e-01,  1.6033e-01],\n",
      "        [-2.5043e-01, -2.7686e-01,  1.3658e-01,  4.8141e-01, -4.3388e-01,\n",
      "         -1.8030e-01, -7.5919e-02,  2.1734e-01, -3.0852e-01,  2.3797e-01],\n",
      "        [-1.6409e-01, -2.0379e-01, -2.0388e-02,  5.0061e-01, -4.9629e-01,\n",
      "         -2.8147e-01, -7.9675e-02,  1.5827e-01, -1.8760e-01,  2.0645e-01],\n",
      "        [-1.7085e-01, -1.5618e-01,  1.4559e-01,  4.3127e-01, -4.1373e-01,\n",
      "         -1.8261e-01, -1.8629e-01,  1.1618e-01, -2.4575e-01,  9.9238e-02],\n",
      "        [-2.7881e-01, -2.2021e-01, -3.7689e-01,  8.0117e-01, -8.5231e-01,\n",
      "         -4.4377e-01,  3.7970e-02,  2.4732e-01, -5.3180e-02,  4.1833e-01],\n",
      "        [-2.0646e-01, -1.3960e-01, -5.9135e-02,  5.1814e-01, -5.7183e-01,\n",
      "         -2.8315e-01, -1.6133e-01,  1.4785e-01, -1.7807e-01,  1.5305e-01],\n",
      "        [-1.1701e-01, -1.2119e-01,  8.4695e-02,  3.9532e-01, -3.6865e-01,\n",
      "         -2.1505e-01, -1.6340e-01,  8.8795e-02, -2.2297e-01,  8.4923e-02],\n",
      "        [-1.4043e-01, -2.7336e-01,  4.4951e-01,  2.1159e-01, -2.1691e-01,\n",
      "          2.4326e-01, -1.5328e-01, -1.0291e-01, -4.6607e-01,  1.5602e-01],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-8.9309e-02, -1.6196e-01,  1.6442e-01,  3.1328e-01, -2.6327e-01,\n",
      "         -1.8395e-01, -1.4089e-01,  9.8340e-02, -2.8585e-01,  7.3534e-02],\n",
      "        [-1.3823e-01, -2.0566e-01,  3.0885e-01,  3.0191e-01, -2.7434e-01,\n",
      "         -4.1819e-02, -1.6050e-01,  5.6947e-02, -3.5588e-01,  9.7774e-02],\n",
      "        [-9.1103e-02, -2.0909e-01,  7.2468e-02,  3.6149e-01, -3.2136e-01,\n",
      "         -2.4558e-01, -7.4231e-02,  1.2629e-01, -2.2951e-01,  1.4575e-01],\n",
      "        [-9.7990e-02, -2.4451e-01,  6.1013e-04,  4.0101e-01, -3.6662e-01,\n",
      "         -2.8774e-01, -1.3966e-02,  1.5312e-01, -2.0084e-01,  1.9950e-01],\n",
      "        [-1.0541e-01, -1.7428e-01,  8.7151e-02,  3.7697e-01, -3.4381e-01,\n",
      "         -2.2936e-01, -1.1966e-01,  1.1038e-01, -2.2552e-01,  1.1985e-01],\n",
      "        [-1.5665e-01, -4.7989e-02, -2.0882e-01,  4.3712e-01, -5.3018e-01,\n",
      "         -3.3574e-01, -1.3822e-01,  1.0610e-01, -1.3961e-01,  5.6374e-02],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-1.0697e-01, -1.8962e-01,  1.5739e-01,  3.0468e-01, -2.8158e-01,\n",
      "         -9.6692e-02, -1.9011e-01,  9.1530e-02, -3.2345e-01,  7.8461e-02],\n",
      "        [-3.3039e-01, -1.9996e-01, -2.0930e-01,  7.8469e-01, -8.6569e-01,\n",
      "         -3.5032e-01, -9.1126e-02,  2.3475e-01, -1.1265e-01,  3.2485e-01],\n",
      "        [-3.9459e-01, -2.3971e-01, -8.4240e-02,  7.4186e-01, -8.5808e-01,\n",
      "         -2.8336e-01, -1.5589e-01,  2.7147e-01, -2.0121e-01,  2.8670e-01],\n",
      "        [-8.9342e-02, -1.9356e-01,  8.3698e-04,  3.9146e-01, -3.5499e-01,\n",
      "         -2.7456e-01, -4.3005e-02,  1.2357e-01, -1.9503e-01,  1.5412e-01],\n",
      "        [-5.1834e-02, -2.6234e-01,  2.3638e-01,  1.8370e-01, -1.2853e-01,\n",
      "          2.8643e-02, -1.3265e-01,  1.7423e-03, -3.9598e-01,  1.0970e-01],\n",
      "        [-1.0088e-01, -7.8874e-02, -1.8159e-01,  5.0732e-01, -5.0223e-01,\n",
      "         -3.4209e-01, -6.7648e-02,  7.9323e-02, -7.3631e-02,  1.4299e-01],\n",
      "        [-5.7036e-02, -1.4565e-01,  1.7718e-01,  2.5235e-01, -1.7796e-01,\n",
      "         -1.6352e-01, -1.0254e-01,  8.2168e-02, -3.1531e-01,  2.5675e-02],\n",
      "        [-1.3505e-01, -1.3536e-01, -1.6692e-01,  5.4446e-01, -5.5300e-01,\n",
      "         -3.4955e-01, -6.7993e-02,  1.2606e-01, -1.0502e-01,  2.1086e-01],\n",
      "        [-1.4394e-01, -1.1728e-01, -3.4591e-02,  4.9154e-01, -4.8919e-01,\n",
      "         -2.7438e-01, -1.3807e-01,  1.0478e-01, -1.5698e-01,  1.4157e-01],\n",
      "        [-3.3156e-01, -2.5027e-01,  4.8504e-01,  4.2669e-01, -4.6001e-01,\n",
      "          2.2127e-01, -1.3316e-01, -1.2589e-02, -4.4851e-01,  2.7217e-01]],\n",
      "       device='cuda:0', grad_fn=<ViewBackward0>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  pd.DataFrame(px_logits)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0  \\\n",
      "0   tensor(-0.1604, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.0787, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.1605, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.2447, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.3148, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.1009, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.0570, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.1351, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.1439, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(-0.3316, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    1  \\\n",
      "0   tensor(-0.1797, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.1776, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.1804, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.1686, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.2160, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.0789, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.1457, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.1354, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.1173, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(-0.2503, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    2  \\\n",
      "0   tensor(-0.0768, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(0.0094, device='cuda:0', grad_fn=<Unbin...   \n",
      "2   tensor(0.0837, device='cuda:0', grad_fn=<Unbin...   \n",
      "3   tensor(0.0530, device='cuda:0', grad_fn=<Unbin...   \n",
      "4   tensor(0.0003, device='cuda:0', grad_fn=<Unbin...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.1816, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(0.1772, device='cuda:0', grad_fn=<Unbin...   \n",
      "61  tensor(-0.1669, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.0346, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(0.4850, device='cuda:0', grad_fn=<Unbin...   \n",
      "\n",
      "                                                    3  \\\n",
      "0   tensor(0.5266, device='cuda:0', grad_fn=<Unbin...   \n",
      "1   tensor(0.3797, device='cuda:0', grad_fn=<Unbin...   \n",
      "2   tensor(0.4467, device='cuda:0', grad_fn=<Unbin...   \n",
      "3   tensor(0.5391, device='cuda:0', grad_fn=<Unbin...   \n",
      "4   tensor(0.5321, device='cuda:0', grad_fn=<Unbin...   \n",
      "..                                                ...   \n",
      "59  tensor(0.5073, device='cuda:0', grad_fn=<Unbin...   \n",
      "60  tensor(0.2524, device='cuda:0', grad_fn=<Unbin...   \n",
      "61  tensor(0.5445, device='cuda:0', grad_fn=<Unbin...   \n",
      "62  tensor(0.4915, device='cuda:0', grad_fn=<Unbin...   \n",
      "63  tensor(0.4267, device='cuda:0', grad_fn=<Unbin...   \n",
      "\n",
      "                                                    4  \\\n",
      "0   tensor(-0.5295, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.3423, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.4311, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.5714, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.6558, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.5022, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.1780, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.5530, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.4892, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(-0.4600, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    5  \\\n",
      "0   tensor(-0.3068, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.2717, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.2223, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.2217, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.2372, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.3421, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.1635, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.3495, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.2744, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(0.2213, device='cuda:0', grad_fn=<Unbin...   \n",
      "\n",
      "                                                    6  \\\n",
      "0   tensor(-0.0767, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.0620, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.1376, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.1844, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.2156, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.0676, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.1025, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.0680, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.1381, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(-0.1332, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    7  \\\n",
      "0   tensor(0.1497, device='cuda:0', grad_fn=<Unbin...   \n",
      "1   tensor(0.1044, device='cuda:0', grad_fn=<Unbin...   \n",
      "2   tensor(0.1328, device='cuda:0', grad_fn=<Unbin...   \n",
      "3   tensor(0.1613, device='cuda:0', grad_fn=<Unbin...   \n",
      "4   tensor(0.2300, device='cuda:0', grad_fn=<Unbin...   \n",
      "..                                                ...   \n",
      "59  tensor(0.0793, device='cuda:0', grad_fn=<Unbin...   \n",
      "60  tensor(0.0822, device='cuda:0', grad_fn=<Unbin...   \n",
      "61  tensor(0.1261, device='cuda:0', grad_fn=<Unbin...   \n",
      "62  tensor(0.1048, device='cuda:0', grad_fn=<Unbin...   \n",
      "63  tensor(-0.0126, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    8  \\\n",
      "0   tensor(-0.1565, device='cuda:0', grad_fn=<Unbi...   \n",
      "1   tensor(-0.1739, device='cuda:0', grad_fn=<Unbi...   \n",
      "2   tensor(-0.2259, device='cuda:0', grad_fn=<Unbi...   \n",
      "3   tensor(-0.2215, device='cuda:0', grad_fn=<Unbi...   \n",
      "4   tensor(-0.2631, device='cuda:0', grad_fn=<Unbi...   \n",
      "..                                                ...   \n",
      "59  tensor(-0.0736, device='cuda:0', grad_fn=<Unbi...   \n",
      "60  tensor(-0.3153, device='cuda:0', grad_fn=<Unbi...   \n",
      "61  tensor(-0.1050, device='cuda:0', grad_fn=<Unbi...   \n",
      "62  tensor(-0.1570, device='cuda:0', grad_fn=<Unbi...   \n",
      "63  tensor(-0.4485, device='cuda:0', grad_fn=<Unbi...   \n",
      "\n",
      "                                                    9  \n",
      "0   tensor(0.2121, device='cuda:0', grad_fn=<Unbin...  \n",
      "1   tensor(0.1335, device='cuda:0', grad_fn=<Unbin...  \n",
      "2   tensor(0.1419, device='cuda:0', grad_fn=<Unbin...  \n",
      "3   tensor(0.1545, device='cuda:0', grad_fn=<Unbin...  \n",
      "4   tensor(0.1643, device='cuda:0', grad_fn=<Unbin...  \n",
      "..                                                ...  \n",
      "59  tensor(0.1430, device='cuda:0', grad_fn=<Unbin...  \n",
      "60  tensor(0.0257, device='cuda:0', grad_fn=<Unbin...  \n",
      "61  tensor(0.2109, device='cuda:0', grad_fn=<Unbin...  \n",
      "62  tensor(0.1416, device='cuda:0', grad_fn=<Unbin...  \n",
      "63  tensor(0.2722, device='cuda:0', grad_fn=<Unbin...  \n",
      "\n",
      "[64 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "## Training Loop \n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\">> Using device: {device}\")\n",
    "\n",
    "# move the model to the device\n",
    "vae = vae.to(device)\n",
    "\n",
    "# training..\n",
    "while epoch < num_epochs:\n",
    "    epoch+= 1\n",
    "    training_epoch_data = defaultdict(list)\n",
    "    vae.train()\n",
    "    \n",
    "    # Go through each batch in the training dataset using the loader\n",
    "    # Note that y is not necessarily known as it is here\n",
    "    #for x, y in train_loader:\n",
    "    for x in train_loader:\n",
    "    \n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBO\n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # gather data for the current bach\n",
    "        for k, v in diagnostics.items():\n",
    "            training_epoch_data[k] += [v.mean().item()]\n",
    "            \n",
    "\n",
    "    # gather data for the full epoch\n",
    "    for k, v in training_epoch_data.items():\n",
    "        training_data[k] += [np.mean(training_epoch_data[k])]\n",
    "\n",
    "    # Evaluate on a single batch, do not propagate gradients\n",
    "    with torch.no_grad():\n",
    "        vae.eval()\n",
    "        \n",
    "        # Just load a single batch from the test loader\n",
    "        #x, y = next(iter(test_loader))\n",
    "        x= next(iter(test_loader))\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # perform a forward pass through the model and compute the ELBOwhy \n",
    "        loss, diagnostics, outputs = vi(vae, x)\n",
    "        \n",
    "        # gather data for the validation step\n",
    "        for k, v in diagnostics.items():\n",
    "            validation_data[k] += [v.mean().item()]\n",
    "    \n",
    "    # Reproduce the figure from the begining of the notebook, plot the training curves and show latent samples\n",
    "    # make_vae_plots(vae, x, y, outputs, training_data, validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confidence interval is a \"confidence interval\" of the mean difference. So it tells you the 95% bounds for the mean difference between two models. The fact that it's positive or negative implies that the mean test error isÂ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs['z']\n",
    "px = vae.sample_from_prior(batch_size=x.size(0))['px']\n",
    "x_samples = px.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([90, 10])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -6.0025,   0.6144,  -7.2811,  -0.7281,  -3.4086,  -0.5898,  -8.4195,\n",
       "        -10.9420,  -6.2398,  -0.8397], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ -6.1260,   0.6893,  -7.4136,  -0.7852,  -3.6001,  -0.5520,  -8.5079,\n",
       "        -11.0923,  -6.4012,  -0.7096], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[910:,:].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4620,  0.2598, -1.6850, -0.0661, -0.7311, -0.1186, -1.9063, -2.4087,\n",
       "        -1.4396, -0.1992], device='cuda:0')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_samples.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'latent_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24060/3126076475.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mVariationalAutoencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'latent_features'"
     ]
    }
   ],
   "source": [
    "VariationalAutoencoder(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee89bb07d3fa5f9c0a8bd127b3056783b076f56308f3ae1a55a1b4c1c97796ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
